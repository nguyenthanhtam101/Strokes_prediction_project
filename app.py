import streamlit as st
import pandas as pd
import numpy as np
import joblib
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import os
import io 
from PIL import Image 
import tensorflow as tf 
from tensorflow.keras.models import load_model
from huggingface_hub import hf_hub_download 
import tensorflow_hub as hub 
from tensorflow.keras.utils import custom_object_scope # <-- TH√äM D√íNG N√ÄY

# --- 1. C·∫§U H√åNH TRANG V√Ä T·∫¢I M√î H√åNH ---

st.set_page_config( page_title="H·ªá Th·ªëng D·ª± ƒêo√°n ƒê·ªôt Qu·ªµ", page_icon="üß†", layout="wide")

# (Gi·ªØ nguy√™n c√°c d√≤ng HF_REPO_ID v√† FILENAME...)
HF_REPO_ID = "tam43621/stroke-predict" 
MODEL_PATH = "models/" 
MODEL_A_FILENAME = MODEL_PATH + "model_A_final.json"
SCALER_A_FILENAME = MODEL_PATH + "scaler_A_final.pkl"
COLS_A_FILENAME = MODEL_PATH + "columns_A_final.pkl"
MODEL_B_FILENAME = MODEL_PATH + "model_B_final.json"
SCALER_B_FILENAME = MODEL_PATH + "scaler_B_final.pkl"
COLS_B_FILENAME = MODEL_PATH + "columns_B_final.pkl"
X_TRAIN_SAMPLE_FILENAME = MODEL_PATH + "X_train_sample_scaled.pkl"
MODEL_C_FILENAME = MODEL_PATH + "model2_C_resnet.h5" 

@st.cache_resource
def load_models_and_data():
    """T·∫£i 3 model, scaler, c·ªôt t·ª´ Hugging Face Hub."""
    try:
        # T·∫£i t·ª´ng file t·ª´ Hugging Face
        model_a_path = hf_hub_download(repo_id=HF_REPO_ID, filename=MODEL_A_FILENAME)
        model_b_path = hf_hub_download(repo_id=HF_REPO_ID, filename=MODEL_B_FILENAME)
        model_c_path = hf_hub_download(repo_id=HF_REPO_ID, filename=MODEL_C_FILENAME)
        scaler_a_path = hf_hub_download(repo_id=HF_REPO_ID, filename=SCALER_A_FILENAME)
        scaler_b_path = hf_hub_download(repo_id=HF_REPO_ID, filename=SCALER_B_FILENAME)
        cols_a_path = hf_hub_download(repo_id=HF_REPO_ID, filename=COLS_A_FILENAME)
        cols_b_path = hf_hub_download(repo_id=HF_REPO_ID, filename=COLS_B_FILENAME)
        train_sample_path = hf_hub_download(repo_id=HF_REPO_ID, filename=X_TRAIN_SAMPLE_FILENAME)

        # T·∫£i model A v√† B
        model_a = xgb.XGBClassifier(); model_a.load_model(model_a_path)
        model_b = xgb.XGBClassifier(); model_b.load_model(model_b_path)
        
        # --- S·ª¨A L·ªñI MODEL C (D√πng custom_object_scope) ---
        # B√°o cho Keras bi·∫øt v·ªÅ c√°c l·ªõp c·ªßa TensorFlow Hub
        # Ch√∫ng ta d√πng 'with' (context manager) thay v√¨ truy·ªÅn dict
        with custom_object_scope({'KerasLayer': hub.KerasLayer}):
             model_c = load_model(model_c_path, compile=False)
        # --- K·∫æT TH√öC S·ª¨A L·ªñI ---
        
        train_sample_scaled = joblib.load(train_sample_path)
        cols_a = joblib.load(cols_a_path); cols_b = joblib.load(cols_b_path)
        
        if not isinstance(train_sample_scaled, pd.DataFrame): train_sample_scaled = pd.DataFrame(train_sample_scaled, columns=cols_a)
        elif list(train_sample_scaled.columns) != list(cols_a): train_sample_scaled.columns = cols_a

        models_data = {
            "model_A": model_a, "scaler_A": joblib.load(scaler_a_path), "cols_A": cols_a,
            "model_B": model_b, "scaler_B": joblib.load(scaler_b_path), "cols_B": cols_b,
            "model_C": model_c,
            "train_sample_scaled": train_sample_scaled
        }
        print("ƒê√£ t·∫£i 3 model v√† d·ªØ li·ªáu m·∫´u t·ª´ Hugging Face th√†nh c√¥ng.")
        return models_data
    except Exception as e: st.error(f"L·ªói khi t·∫£i model t·ª´ Hugging Face: {e}"); st.exception(e); return None

models_data = load_models_and_data()
if models_data is None: st.warning("Kh√¥ng t·∫£i ƒë∆∞·ª£c model."); st.stop()
numerical_cols_s = ['age', 'avg_glucose_level', 'bmi']
# --- Gi·∫£ ƒë·ªãnh k√≠ch th∆∞·ªõc ·∫£nh Model C (thay ƒë·ªïi n·∫øu c·∫ßn) ---
IMG_SIZE = (224, 224) 


# --- H√ÄM LOGIC CHO MODEL A & B (Gi·ªØ nguy√™n) ---
def predict_final_risk_v3(patient_health_df, patient_symptoms_df):
    health_original = patient_health_df.copy(); symptoms_original = patient_symptoms_df.copy()
    age=health_original.get('age', pd.Series([0])).iloc[0]; bmi=health_original.get('bmi', pd.Series([np.nan])).iloc[0]
    glucose=health_original.get('avg_glucose_level', pd.Series([0])).iloc[0]; hypertension=health_original.get('hypertension', pd.Series([0])).iloc[0]
    heart_disease=health_original.get('heart_disease', pd.Series([0])).iloc[0]; irregular_heartbeat=symptoms_original.get('Irregular Heartbeat', pd.Series([0])).iloc[0]
    bmi_value_for_check = bmi if pd.notna(bmi) else 0

    if pd.notna(age) and pd.notna(irregular_heartbeat) and age > 65 and irregular_heartbeat == 1: return "CAO (D·ª±a tr√™n rung nhƒ© v√† tu·ªïi t√°c)", 0.95, "red_flag"
    if pd.notna(age) and pd.notna(glucose) and pd.notna(hypertension) and pd.notna(heart_disease) and \
       age < 40 and bmi_value_for_check < 30 and glucose < 140 and hypertension == 0 and heart_disease == 0: return "TH·∫§P (D·ª±a tr√™n ki·∫øn th·ª©c y khoa)", 0.05, "green_flag"

    model_A = models_data["model_A"]; model_B = models_data["model_B"]; scaler_A = models_data["scaler_A"]
    scaler_B = models_data["scaler_B"]; columns_A = models_data["cols_A"]; columns_B = models_data["cols_B"]
    health_df_processed = health_original.reindex(columns=columns_A, fill_value=0)
    for col in numerical_cols_s: health_df_processed[col] = pd.to_numeric(health_df_processed[col], errors='coerce')
    mean_values = models_data["train_sample_scaled"][numerical_cols_s].mean() if models_data["train_sample_scaled"] is not None else 0
    health_df_processed = health_df_processed.fillna(mean_values)
    prob_A = 0.0
    try:
        health_df_processed[numerical_cols_s] = health_df_processed[numerical_cols_s].astype(float)
        health_df_processed[numerical_cols_s] = scaler_A.transform(health_df_processed[numerical_cols_s])
        prob_A = model_A.predict_proba(health_df_processed)[:, 1][0]
    except Exception as e_scale_A: st.warning(f"L·ªói scale A: {e_scale_A}")

    symptoms_df_scaled = symptoms_original.copy()
    if 'age' in symptoms_df_scaled.columns and 'Age' not in symptoms_df_scaled.columns: symptoms_df_scaled=symptoms_df_scaled.rename(columns={'age': 'Age'})
    prob_B = 0.0
    if 'Age' in symptoms_df_scaled.columns and pd.to_numeric(symptoms_df_scaled['Age'], errors='coerce').notna().all():
        symptoms_df_scaled['Age'] = pd.to_numeric(symptoms_df_scaled['Age'], errors='coerce')
        try:
            symptoms_df_scaled[['Age']] = symptoms_df_scaled[['Age']].astype(float) # ƒê·∫£m b·∫£o ki·ªÉu float
            symptoms_df_scaled[['Age']] = scaler_B.transform(symptoms_df_scaled[['Age']])
            symptoms_for_predict = symptoms_df_scaled.reindex(columns=columns_B, fill_value=0)
            prob_B = model_B.predict_proba(symptoms_for_predict)[:, 1][0]
        except Exception as e_scale_B: st.warning(f"L·ªói scale B: {e_scale_B}")

    if prob_B >= 0.5: return "CAO (D·ª±a tr√™n tri·ªáu ch·ª©ng c·∫•p t√≠nh)", prob_B, "ai_model_b"
    elif prob_A >= 0.2: return "TRUNG B√åNH (D·ª±a tr√™n y·∫øu t·ªë r·ªßi ro ti·ªÅm ·∫©n)", prob_A, "ai_model_a"
    else: return "TH·∫§P", max(prob_A, prob_B), "ai_low"

# --- 3. GIAO DI·ªÜN ·ª®NG D·ª§NG ---

st.title("üß† H·ªá Th·ªëng S√†ng L·ªçc & D·ª± ƒêo√°n ƒê·ªôt Qu·ªµ (3 Model)")
st.markdown("·ª®ng d·ª•ng k·∫øt h·ª£p AI (tabular, h√¨nh ·∫£nh) v√† logic y khoa ƒë·ªÉ ƒë√°nh gi√° nguy c∆° ƒë·ªôt qu·ªµ.")

# --- C·∫¨P NH·∫¨T: Th√™m Tab 3 cho Model C ---
tab_names = ["D√†nh cho B·ªánh nh√¢n (Model A+B)", "D√†nh cho B√°c sƒ© (Model A+B)", "Ch·∫©n ƒëo√°n H√¨nh ·∫£nh (Model C)"]
tab_patient, tab_doctor, tab_image = st.tabs(tab_names)

# --- TAB D√ÄNH CHO B·ªÜNH NH√ÇN (Gi·ªØ nguy√™n) ---
with tab_patient:
    st.header("C√¥ng C·ª• T·ª± ƒê√°nh Gi√° Nguy C∆°")
    st.write("Vui l√≤ng cung c·∫•p c√°c th√¥ng tin d∆∞·ªõi ƒë√¢y ƒë·ªÉ h·ªá th·ªëng ph√¢n t√≠ch.")
    with st.form("patient_form"):
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("Th√¥ng tin H·ªì s∆° S·ª©c kh·ªèe")
            age = st.number_input("Tu·ªïi c·ªßa b·∫°n", min_value=1, max_value=120, value=None, step=1, placeholder="Nh·∫≠p tu·ªïi...", key="p_age")
            gender_selected = st.radio("Gi·ªõi t√≠nh", ["Nam", "N·ªØ"], index=None, key="p_gender")
            avg_glucose_level = st.number_input("M·ª©c ƒë∆∞·ªùng huy·∫øt TB (mg/dL)", min_value=50.0, max_value=300.0, value=None, step=0.1, format="%.1f", placeholder="V√≠ d·ª•: 100.0", key="p_glucose")
            bmi = st.number_input("Ch·ªâ s·ªë BMI", min_value=10.0, max_value=70.0, value=None, step=0.1, format="%.1f", placeholder="V√≠ d·ª•: 22.5", key="p_bmi")
            hypertension = 1 if st.checkbox("Cao huy·∫øt √°p?", key="p_ht") else 0
            heart_disease = 1 if st.checkbox("B·ªánh tim?", key="p_hd") else 0
            smoking_status_options = ["Ch∆∞a bao gi·ªù h√∫t", "ƒê√£ t·ª´ng h√∫t", "ƒêang h√∫t thu·ªëc", "Kh√¥ng r√µ"]
            smoking_status = st.selectbox("T√¨nh tr·∫°ng h√∫t thu·ªëc", smoking_status_options, index=None, placeholder="Ch·ªçn t√¨nh tr·∫°ng...", key="p_smoke")
            smoking_formerly = 1 if smoking_status == "ƒê√£ t·ª´ng h√∫t" else 0
            smoking_never = 1 if smoking_status == "Ch∆∞a bao gi·ªù h√∫t" else 0
            smoking_smokes = 1 if smoking_status == "ƒêang h√∫t thu·ªëc" else 0
        with col2:
            st.subheader("Th√¥ng tin Tri·ªáu ch·ª©ng (n·∫øu c√≥)")
            symptoms = {}
            symptom_columns = models_data["cols_B"].tolist(); symptom_columns.remove('Age')
            symptom_translation = {
                'Irregular Heartbeat': 'Nh·ªãp tim kh√¥ng ƒë·ªÅu (Rung nhƒ©)', 'High Blood Pressure': 'Huy·∫øt √°p cao (tri·ªáu ch·ª©ng)',
                'Chest Pain': 'ƒêau ng·ª±c', 'Shortness of Breath': 'Kh√≥ th·ªü', 'Dizziness': 'Ch√≥ng m·∫∑t, x√¢y x·∫©m',
                'Fatigue & Weakness': 'M·ªát m·ªèi & Y·∫øu c∆°', 'Swelling (Edema)': 'Ph√π (s∆∞ng) tay ch√¢n',
                'Pain in Neck/Jaw/Shoulder/Back': 'ƒêau c·ªï/h√†m/vai/l∆∞ng', 'Excessive Sweating': 'ƒê·ªï m·ªì h√¥i nhi·ªÅu',
                'Persistent Cough': 'Ho dai d·∫≥ng', 'Nausea/Vomiting': 'Bu·ªìn n√¥n/N√¥n',
                'Chest Discomfort (Activity)': 'Kh√≥ ch·ªãu ·ªü ng·ª±c (khi ho·∫°t ƒë·ªông)', 'Cold Hands/Feet': 'L·∫°nh tay/ch√¢n',
                'Snoring/Sleep Apnea': 'Ng√°y/Ng∆∞ng th·ªü khi ng·ªß', 'Anxiety/Feeling of Doom': 'Lo l·∫Øng/C·∫£m gi√°c b·∫•t an'
            }
            for symptom_name in symptom_columns:
                label = symptom_translation.get(symptom_name, symptom_name.replace('_', ' ').title())
                key = f"p_sym_{symptom_name}"; symptoms[symptom_name] = 1 if st.checkbox(label, key=key) else 0
        submitted = st.form_submit_button("B·∫ÆT ƒê·∫¶U D·ª∞ ƒêO√ÅN")
    if submitted:
        if age is None or gender_selected is None or avg_glucose_level is None or bmi is None or smoking_status is None:
            st.error("Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß th√¥ng tin H·ªì s∆° S·ª©c kh·ªèe.")
        else:
            with st.spinner("H·ªá th·ªëng ƒëang ph√¢n t√≠ch..."):
                gender_Male = 1 if gender_selected == "Nam" else 0
                health_data = {'age': [age], 'avg_glucose_level': [avg_glucose_level], 'bmi': [bmi], 'hypertension': [hypertension], 'heart_disease': [heart_disease], 'gender_Male': [gender_Male], 'smoking_status_formerly smoked': [smoking_formerly], 'smoking_status_never smoked': [smoking_never], 'smoking_status_smokes': [smoking_smokes]}
                patient_health_df = pd.DataFrame(health_data)
                patient_symptoms_df = pd.DataFrame([symptoms]); patient_symptoms_df['Age'] = age; patient_symptoms_df['age'] = age
                risk_level, probability, source = predict_final_risk_v3(patient_health_df, patient_symptoms_df)
                st.subheader("K·∫øt Qu·∫£ Ph√¢n T√≠ch")
                if "CAO" in risk_level: st.error(f"**Nguy c∆°: {risk_level}** ({probability*100:.2f}%)")
                elif "TRUNG B√åNH" in risk_level: st.warning(f"**Nguy c∆°: {risk_level}** ({probability*100:.2f}%)")
                else: st.success(f"**Nguy c∆°: {risk_level}** ({probability*100:.2f}%)")
                if "CAO" in risk_level: st.warning("C·∫£nh b√°o: Nguy c∆° cao. Vui l√≤ng li√™n h·ªá c∆° s·ªü y t·∫ø g·∫ßn nh·∫•t.")
                elif "TRUNG B√åNH" in risk_level: st.info("Khuy·∫øn ngh·ªã: C√≥ y·∫øu t·ªë r·ªßi ro. Duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh, theo d√µi s·ª©c kh·ªèe.")
                else: st.info("Khuy·∫øn ngh·ªã: Kh√¥ng ph√°t hi·ªán nguy c∆° r√µ r√†ng. Ti·∫øp t·ª•c duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh.")

# --- TAB D√ÄNH CHO B√ÅC Sƒ® (Gi·ªØ nguy√™n) ---
with tab_doctor:
    st.header("Dashboard H·ªó Tr·ª£ Ch·∫©n ƒêo√°n")
    st.subheader("1. S√†ng l·ªçc B·ªánh nh√¢n h√†ng lo·∫°t")
    uploaded_file = st.file_uploader("T·∫£i l√™n file Excel/CSV danh s√°ch b·ªánh nh√¢n", type=["csv", "xlsx"], key="d_uploader")
    COLUMN_MAP = {
        'age': ['age', 'tu·ªïi', 'tuoi'], 'avg_glucose_level': ['avg_glucose_level', 'glucose', 'ƒë∆∞·ªùng huy·∫øt', 'duong huyet'],
        'bmi': ['bmi', 'ch·ªâ s·ªë bmi', 'chiso bmi'], 'hypertension': ['hypertension', 'cao huy·∫øt √°p', 'huy·∫øt √°p cao', 'ha', 'tang huyet ap'],
        'heart_disease': ['heart_disease', 'b·ªánh tim', 'benh tim'], 'gender': ['gender', 'gi·ªõi t√≠nh', 'ph√°i', 'gioi tinh'],
        'smoking_status': ['smoking_status', 'h√∫t thu·ªëc', 'hut thuoc', 'tinh trang hut thuoc'],
        'Irregular Heartbeat': ['irregular heartbeat', 'nh·ªãp tim kh√¥ng ƒë·ªÅu', 'rung nhƒ©', 'nhip tim khong deu'],
        'High Blood Pressure': ['high blood pressure', 'huy·∫øt √°p cao (tri·ªáu ch·ª©ng)', 'huyet ap cao'], 'Chest Pain': ['chest pain', 'ƒëau ng·ª±c', 'dau nguc'],
        'Shortness of Breath': ['shortness of breath', 'kh√≥ th·ªü', 'kho tho'], 'Dizziness': ['dizziness', 'ch√≥ng m·∫∑t', 'chong mat'],
        'Fatigue & Weakness': ['fatigue & weakness', 'm·ªát m·ªèi', 'met moi', 'y·∫øu c∆°', 'yeu co'], 'Swelling (Edema)': ['swelling (edema)', 'ph√π', 's∆∞ng', 'phu'],
        'Pain in Neck/Jaw/Shoulder/Back': ['pain in neck/jaw/shoulder/back', 'ƒëau c·ªï vai g√°y', 'dau co vai gay'], 'Excessive Sweating': ['excessive sweating', 'ƒë·ªï m·ªì h√¥i', 'do mo hoi'],
        'Persistent Cough': ['persistent cough', 'ho dai d·∫≥ng', 'ho keo dai'], 'Nausea/Vomiting': ['nausea/vomiting', 'bu·ªìn n√¥n', 'non'],
        'Chest Discomfort (Activity)': ['chest discomfort (activity)', 'kh√≥ ch·ªãu ng·ª±c', 'kho chiu nguc'], 'Cold Hands/Feet': ['cold hands/feet', 'l·∫°nh tay ch√¢n', 'lanh tay chan'],
        'Snoring/Sleep Apnea': ['snoring/sleep apnea', 'ng√°y', 'ng∆∞ng th·ªü khi ng·ªß'], 'Anxiety/Feeling of Doom': ['anxiety/feeling of doom', 'lo l·∫Øng', 'b·∫•t an'],
        'id': ['id', 'm√£ b·ªánh nh√¢n', 'm√£ bn', 'patient id'], 'name': ['name', 'h·ªç t√™n', 't√™n', 'ten benh nhan']
    }

    def find_col_name(df_columns, synonym_list):
        for name in synonym_list:
            if name in df_columns: return name
        return None

    if 'processed_df' not in st.session_state: st.session_state['processed_df'] = None
    if 'shap_data_dict' not in st.session_state: st.session_state['shap_data_dict'] = {}
    if 'original_df_for_display' not in st.session_state: st.session_state['original_df_for_display'] = None

    if uploaded_file:
        with st.spinner("ƒêang x·ª≠ l√Ω file..."):
            try:
                bytes_data = uploaded_file.getvalue(); encodings_to_try = ['utf-8', 'cp1258', 'latin1']; df_patients = None
                for enc in encodings_to_try:
                    try:
                        string_io = io.StringIO(bytes_data.decode(enc))
                        df_patients = pd.read_csv(string_io, na_values=['N/A', 'NA', '']) if uploaded_file.name.endswith('csv') else pd.read_excel(io.BytesIO(bytes_data), na_values=['N/A', 'NA', ''])
                        break
                    except UnicodeDecodeError: continue
                    except Exception as read_err: st.error(f"L·ªói ƒë·ªçc file: {read_err}"); st.stop()
                if df_patients is None: st.error("Kh√¥ng th·ªÉ ƒë·ªçc file encoding."); st.stop()

                df_original_copy = df_patients.copy() 
                df_patients_normalized = df_patients.copy(); df_patients_normalized.columns = df_patients_normalized.columns.str.lower().str.strip()
                uploaded_cols_normalized = df_patients_normalized.columns.tolist()
                health_cols_needed = models_data["cols_A"].tolist(); symptoms_cols_needed = models_data["cols_B"].tolist()
                results = []; processed_rows_for_shap = {}
                age_col_name = find_col_name(uploaded_cols_normalized, COLUMN_MAP['age'])
                if age_col_name is None: st.error("L·ªói: File thi·∫øu c·ªôt 'age'/'tu·ªïi'."); st.stop()
                id_col_name = find_col_name(uploaded_cols_normalized, COLUMN_MAP.get('id', ['id'])) 

                for index, row in df_patients_normalized.iterrows(): 
                    patient_key = index 
                    row_age = pd.to_numeric(row[age_col_name], errors='coerce')
                    if pd.isna(row_age): results.append({"Nguy c∆°": f"L·ªói: Tu·ªïi", "X√°c su·∫•t": 0}); continue

                    health_data = {'age': row_age}; glucose_col = find_col_name(uploaded_cols_normalized, COLUMN_MAP['avg_glucose_level'])
                    health_data['avg_glucose_level'] = pd.to_numeric(row.get(glucose_col, np.nan), errors='coerce')
                    bmi_col = find_col_name(uploaded_cols_normalized, COLUMN_MAP['bmi'])
                    health_data['bmi'] = pd.to_numeric(row.get(bmi_col, np.nan), errors='coerce')
                    ht_col = find_col_name(uploaded_cols_normalized, COLUMN_MAP['hypertension'])
                    health_data['hypertension'] = 1 if ht_col and str(row.get(ht_col, 0)).lower() in ['yes', 'c√≥', '1'] else 0
                    hd_col = find_col_name(uploaded_cols_normalized, COLUMN_MAP['heart_disease'])
                    health_data['heart_disease'] = 1 if hd_col and str(row.get(hd_col, 0)).lower() in ['yes', 'c√≥', '1'] else 0
                    gender_col = find_col_name(uploaded_cols_normalized, COLUMN_MAP['gender'])
                    gender_val = row.get(gender_col) if gender_col else None
                    health_data['gender_Male'] = 1 if (gender_val and str(gender_val).lower() in ['nam', 'male', 'm']) else 0
                    smoking_col = find_col_name(uploaded_cols_normalized, COLUMN_MAP['smoking_status'])
                    smoking_val = row.get(smoking_col) if smoking_col else None
                    health_data['smoking_status_formerly smoked']=1 if (smoking_val and str(smoking_val).lower() in ['ƒë√£ t·ª´ng h√∫t', 'formerly smoked','da tung hut']) else 0
                    health_data['smoking_status_never smoked']=1 if (smoking_val and str(smoking_val).lower() in ['ch∆∞a bao gi·ªù h√∫t', 'never smoked','chua bao gio hut']) else 0
                    health_data['smoking_status_smokes']=1 if (smoking_val and str(smoking_val).lower() in ['ƒëang h√∫t thu·ªëc', 'smokes','dang hut thuoc']) else 0
                    health_df = pd.DataFrame([health_data])

                    symptoms_data = {'Age': row_age}
                    for col_name_model in symptoms_cols_needed:
                        if col_name_model == 'Age': continue
                        synonyms = COLUMN_MAP.get(col_name_model, [col_name_model.lower().strip()])
                        col_name_upload = find_col_name(uploaded_cols_normalized, synonyms)
                        raw_value = row.get(col_name_upload, 0) if col_name_upload else 0
                        symptoms_data[col_name_model] = 1 if str(raw_value).lower() in ['yes', 'c√≥', '1'] else 0
                    symptoms_df = pd.DataFrame([symptoms_data])
                    symptoms_df['age'] = row_age

                    try:
                        mean_values = models_data["train_sample_scaled"][numerical_cols_s].mean() if models_data["train_sample_scaled"] is not None else 0
                        health_df_filled = health_df.fillna(mean_values) 
                        risk, prob, _ = predict_final_risk_v3(health_df_filled.copy(), symptoms_df.copy())
                        results.append({"Nguy c∆°": risk, "X√°c su·∫•t": prob})
                        processed_rows_for_shap[patient_key] = health_df_filled 
                    except Exception as pred_e:
                        results.append({"Nguy c∆°": f"L·ªói d·ª± ƒëo√°n", "X√°c su·∫•t": 0})
                        st.warning(f"L·ªói d·ª± ƒëo√°n BN index {index}: {pred_e}")

                df_results = pd.DataFrame(results)
                df_final = pd.concat([df_original_copy.reset_index(drop=True), df_results.reset_index(drop=True)], axis=1)
                df_final = df_final.sort_values(by="X√°c su·∫•t", ascending=False)
                st.subheader("K·∫øt qu·∫£ S√†ng l·ªçc (ƒê√£ s·∫Øp x·∫øp ∆∞u ti√™n)")
                st.dataframe(df_final)

                st.session_state['processed_df'] = df_final
                st.session_state['shap_data_dict'] = processed_rows_for_shap
                st.session_state['original_df_for_display'] = df_original_copy 
            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói nghi√™m tr·ªçng khi x·ª≠ l√Ω file: {e}")
                st.exception(e)
                st.info("M·∫πo: ƒê·∫£m b·∫£o file CSV/Excel h·ª£p l·ªá v√† c√≥ c·ªôt 'age'/'tu·ªïi'.")
                st.session_state['processed_df'] = None
                st.session_state['shap_data_dict'] = {}
                st.session_state['original_df_for_display'] = None

    # --- PH·∫¶N 2: GI·∫¢I TH√çCH SHAP T∆Ø∆†NG T√ÅC (Gi·ªØ nguy√™n) ---
    st.subheader("2. Gi·∫£i th√≠ch Ca b·ªánh (SHAP - Model A)")
    if st.session_state.get('processed_df') is not None:
        df_display = st.session_state['processed_df']
        shap_data_dict = st.session_state['shap_data_dict']
        df_original_display = st.session_state['original_df_for_display']

        id_col_orig = find_col_name(df_original_display.columns, COLUMN_MAP.get('id', ['id']))
        name_col_orig = find_col_name(df_original_display.columns, COLUMN_MAP.get('name', ['name']))
        display_options = []; option_to_index_map = {}
        for index in df_display.index: 
            label = f"H√†ng {index+2}" # Nh√£n m·∫∑c ƒë·ªãnh
            if id_col_orig and pd.notna(df_original_display.loc[index, id_col_orig]):
                label += f" (ID: {df_original_display.loc[index, id_col_orig]})"
            if name_col_orig and pd.notna(df_original_display.loc[index, name_col_orig]):
                 label += f" - {df_original_display.loc[index, name_col_orig]}"
            display_options.append(label)
            option_to_index_map[label] = index 

        selected_display_option = st.selectbox(
            "Ch·ªçn b·ªánh nh√¢n ƒë·ªÉ gi·∫£i th√≠ch:",
            options=[""] + display_options, index=0, key="d_shap_select"
        )
        if selected_display_option:
            selected_index = option_to_index_map[selected_display_option] 
            patient_info_original = df_original_display.iloc[[selected_index]]
            st.write("Th√¥ng tin b·ªánh nh√¢n ƒë√£ ch·ªçn (d·ªØ li·ªáu g·ªëc):")
            st.dataframe(patient_info_original)
            patient_health_data_for_shap = shap_data_dict.get(selected_index) 
            if patient_health_data_for_shap is None:
                st.warning(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω cho b·ªánh nh√¢n t·∫°i index {selected_index}.")
            elif st.button(f"Ch·∫°y gi·∫£i th√≠ch cho {selected_display_option}", key="d_shap_run_selected"):
                with st.spinner("ƒêang t√≠nh to√°n SHAP (c√≥ th·ªÉ m·∫•t v√†i gi√¢y)..."):
                    try:
                        model_A = models_data["model_A"]; scaler_A = models_data["scaler_A"]
                        columns_A = models_data["cols_A"]; train_sample = models_data["train_sample_scaled"]
                        if train_sample is None: st.error("Thi·∫øu d·ªØ li·ªáu m·∫´u."); st.stop()

                        patient_processed = patient_health_data_for_shap.reindex(columns=columns_A, fill_value=0)
                        for col in numerical_cols_s: patient_processed[col] = pd.to_numeric(patient_processed[col], errors='coerce')
                        mean_vals_shap = train_sample[numerical_cols_s].mean()
                        patient_processed = patient_processed.fillna(mean_vals_shap)
                        patient_processed[numerical_cols_s] = scaler_A.transform(patient_processed[numerical_cols_s])

                        def predict_proba_A(data):
                            if not isinstance(data, pd.DataFrame): data_df = pd.DataFrame(data, columns=columns_A)
                            else: data_df = data.copy()
                            for col in numerical_cols_s: data_df[col] = pd.to_numeric(data_df[col], errors='coerce')
                            data_df = data_df.fillna(mean_vals_shap)
                            data_reindexed = data_df.reindex(columns=columns_A, fill_value=0)
                            data_reindexed[numerical_cols_s] = data_reindexed[numerical_cols_s].astype(float)
                            data_reindexed[numerical_cols_s] = scaler_A.transform(data_reindexed[numerical_cols_s])
                            return model_A.predict_proba(data_reindexed)[:, 1]

                        explainer_background = shap.sample(train_sample, min(50, len(train_sample)))
                        if not isinstance(explainer_background, pd.DataFrame): explainer_background = pd.DataFrame(explainer_background, columns=columns_A)
                        explainer = shap.KernelExplainer(predict_proba_A, explainer_background)
                        shap_values = explainer.shap_values(patient_processed.to_numpy())
                        st.write("Bi·ªÉu ƒë·ªì SHAP gi·∫£i th√≠ch c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng:")
                        fig, ax = plt.subplots()
                        feature_names_vietnamese = { 
                            'age': 'Tu·ªïi', 'avg_glucose_level': 'ƒê∆∞·ªùng huy·∫øt TB', 'bmi': 'Ch·ªâ s·ªë BMI',
                            'hypertension': 'Cao huy·∫øt √°p (N·ªÅn)', 'heart_disease': 'B·ªánh tim (N·ªÅn)',
                            'gender_Male': 'Gi·ªõi t√≠nh Nam', 'smoking_status_formerly smoked': 'ƒê√£ t·ª´ng h√∫t',
                            'smoking_status_never smoked': 'Ch∆∞a bao gi·ªù h√∫t', 'smoking_status_smokes': 'ƒêang h√∫t thu·ªëc'
                        }
                        display_feature_names = [feature_names_vietnamese.get(col, col) for col in columns_A]
                        expected_value_shap = explainer.expected_value
                        if isinstance(expected_value_shap, (np.ndarray, list)): expected_value_shap = expected_value_shap[0]
                        shap.waterfall_plot(shap.Explanation(values=shap_values[0], base_values=expected_value_shap,
                                                             data=patient_processed.iloc[0].to_numpy(), feature_names=display_feature_names))
                        st.pyplot(fig, bbox_inches='tight'); plt.close(fig)
                        st.info(""" **C√°ch ƒë·ªçc bi·ªÉu ƒë·ªì:** (Gi·ªØ nguy√™n) """)
                    except Exception as shap_e:
                        st.error(f"L·ªói khi t√≠nh to√°n ho·∫∑c v·∫Ω SHAP: {shap_e}"); st.exception(shap_e)
    else:
        st.info("Vui l√≤ng t·∫£i l√™n v√† x·ª≠ l√Ω file danh s√°ch b·ªánh nh√¢n ƒë·ªÉ k√≠ch ho·∫°t t√≠nh nƒÉng gi·∫£i th√≠ch.")


# --- PH·∫¶N M·ªöI: TAB D√ÄNH CHO MODEL C (H√åNH ·∫¢NH) ---
with tab_image:
    st.header("Model C: Ph√¢n t√≠ch H√¨nh ·∫£nh Y khoa (CT N√£o)")
    st.info("T·∫£i l√™n ·∫£nh CT n√£o ƒë·ªÉ m√¥ h√¨nh ph√¢n t√≠ch (Hemorrhagic - Ch·∫£y m√°u vs Normal - B√¨nh th∆∞·ªùng).")

    img_file = st.file_uploader("T·∫£i l√™n ·∫£nh (jpg, jpeg, png)", type=["jpg", "jpeg", "png"], key="c_uploader")

    if img_file:
        st.image(img_file, caption="·∫¢nh ƒë√£ t·∫£i l√™n.", use_column_width=True)

        if st.button("B·∫Øt ƒë·∫ßu Ph√¢n t√≠ch ·∫¢nh", key="c_run"):
            with st.spinner("ƒêang x·ª≠ l√Ω ·∫£nh... (C√≥ th·ªÉ m·∫•t m·ªôt l√∫c)"):
                try:
                    model_C = models_data["model_C"]

                    # 1. ƒê·ªçc v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh
                    image = Image.open(img_file).convert('RGB')
                    
                    # 2. Resize v·ªÅ k√≠ch th∆∞·ªõc model C ƒë∆∞·ª£c hu·∫•n luy·ªán (Gi·∫£ ƒë·ªãnh 224x224)
                    # H√£y thay ƒë·ªïi IMG_SIZE ·ªü ƒë·∫ßu file n·∫øu model c·ªßa b·∫°n d√πng k√≠ch th∆∞·ªõc kh√°c
                    image_resized = image.resize(IMG_SIZE) 
                    
                    # 3. Chu·∫©n h√≥a (Gi·∫£ ƒë·ªãnh chu·∫©n h√≥a v·ªÅ [0, 1])
                    img_array = np.array(image_resized)
                    img_array_normalized = img_array / 255.0 
                    
                    # 4. T·∫°o batch (1, 224, 224, 3)
                    img_batch = np.expand_dims(img_array_normalized, axis=0)

                    # 5. D·ª± ƒëo√°n
                    prediction = model_C.predict(img_batch)
                    prob = prediction[0][0] # L·∫•y x√°c su·∫•t t·ª´ neuron output

                    st.subheader("K·∫øt qu·∫£ Ph√¢n t√≠ch H√¨nh ·∫£nh:")
                    
                    # QUAN TR·ªåNG: D·ª±a tr√™n code c≈© c·ªßa b·∫°n:
                    # L·ªõp 0: Hemorrhagic
                    # L·ªõp 1: NORMAL
                    # Model (binary) d·ª± ƒëo√°n x√°c su·∫•t c·ªßa L·ªõp 1 (NORMAL)
                    
                    if prob > 0.5:
                        st.success(f"**K·∫øt lu·∫≠n: NORMAL (B√¨nh th∆∞·ªùng)**")
                        st.progress(prob)
                        st.write(f"ƒê·ªô ch·∫Øc ch·∫Øn (Normal): {prob*100:.2f}%")
                    else:
                        st.error(f"**K·∫øt lu·∫≠n: HEMORRHAGIC (Ch·∫£y m√°u)**")
                        st.progress(1.0 - prob)
                        st.write(f"ƒê·ªô ch·∫Øc ch·∫Øn (Hemorrhagic): {(1-prob)*100:.2f}%")
                        st.warning("C·∫£nh b√°o: Ph√°t hi·ªán d·∫•u hi·ªáu ch·∫£y m√°u. C·∫ßn xem x√©t y t·∫ø ngay l·∫≠p t·ª©c.")

                except Exception as e:
                    st.error(f"L·ªói khi ph√¢n t√≠ch ·∫£nh: {e}")
                    st.exception(e)